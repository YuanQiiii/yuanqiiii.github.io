---
title: 构建可扩展的实时系统——以 `arbitrage-engine` 为例
description: 详细探讨构建一个可扩展、高可用的系统所依赖的几大核心支柱
date: 2025-06-26T00:00:00.000Z
tags:
  - 系统设计
  - 微服务
  - 事件驱动
  - Kafka
author: shihuaidexianyu
---

### **教程：构建可扩展的实时系统——以 `arbitrage-engine` 为例**

我们以一个真实的高性能交易模拟系统 `arbitrage-engine` 为例，详细探讨构建一个可扩展、高可用的系统所依赖的几大核心支柱：

* **微服务架构 (Microservice Architecture)**
* **事件驱动架构 (Event-Driven Architecture - EDA)**
* **Apache Kafka 事件流平台**
* **服务发现 (Service Discovery)**
* **单元测试中的模拟（Mocking）**
* **符号链接（Symbolic Link）的妙用**

我们将看到，这些概念并非孤立存在，而是相辅相成，共同构成了项目中那个强大而灵活的系统。

#### **第一部分：蓝图——微服务架构 (Microservice Architecture)**

首先，我们来看整个系统的骨架——微服务架构。

**1. 什么是微服务？**

微服务架构是一种将大型、复杂的应用程序拆分成一组小型、独立、可独立部署的服务的风格。每个服务都围绕着一个特定的业务功能构建，并通过定义良好的 API 进行通信。

**2. `arbitrage-engine` 是如何体现的？**

项目正是微服务架构的教科书式案例。并没有把所有功能都写在一个巨大的单体应用里，而是将其拆分成了多个各司其职的独立服务：

* **`api_gateway`**: 系统的统一入口，负责处理所有外部 HTTP 请求，是整个系统的门面。
* **`matching_engine`**: 核心的撮合引擎，只关心一件事——如何高效地匹配买卖订单。
* **`data_recorder`**: 数据持久化服务，负责将交易数据安全地存入 PostgreSQL 数据库。
* **`clock_service` & `event_generator`**: 模拟驱动服务，共同为系统提供“心跳”和模拟的市场事件，让整个模拟世界运转起来。
* **`ai_agent`**: 智能交易代理，它是一个独立的决策单元，模拟交易者在市场中的行为。

**3. 为什么选择微服务？**

* **独立部署与扩展**: 可以独立更新或重启 `ai_agent` 服务，而不会影响到 `matching_engine`。如果撮合压力变大，可以只针对 `matching_engine` 服务增加实例数量，实现水平扩展。
* **技术异构性**: 虽然整个项目主要使用 Rust，但微服务架构允许在未来使用其他技术（如用 Python 写 AI 模型）来构建新的服务。
* **职责清晰，易于维护**: 每个服务代码库都更小、更专注，使得开发者更容易理解和维护。

-----

#### **第二部分：灵魂——事件驱动架构 (EDA) 与 Apache Kafka**

如果说微服务是系统的骨架，那么事件驱动就是系统的灵魂，而 Kafka 则是连接这一切的“神经网络”。

**1. 什么是事件驱动架构？**

在传统的请求-响应模式中，服务 A 调用服务 B，然后等待 B 的响应。但在事件驱动架构中，服务之间通过\*\*异步的“事件”\*\*进行通信。一个服务发布一个事件（宣告“某事已发生”），然后就不再关心谁会处理它。其他对此事件感兴趣的服务会订阅并做出响应。

这种模式极大地降低了服务之间的耦合度。

**2. Kafka：事件的中枢**

Apache Kafka 在项目中扮演了这个事件流平台的角色。它是一个高性能的、分布式的消息总线，所有的“事件”都在这里流转。

让我们来看看 Kafka 的核心概念在项目中的具体体现：

* **生产者 (Producer)**：任何向 Kafka 发送事件的服务都是生产者。

  * `api_gateway` 接收到前端的下单请求后，它不直接调用撮合引擎，而是生产一个 `order_command` 事件发送给 Kafka。
  * `clock_service` 定期生产 `system_tick` 事件，广播给整个系统。
  * `matching_engine` 在撮合成功后，会生产 `trade_executed` 事件。

* **消费者 (Consumer)**：任何从 Kafka 读取事件的服务都是消费者。

  * `matching_engine` 消费 `order_command` 事件来执行撮合。
  * `data_recorder` 消费 `trade_executed` 事件，将其写入数据库。
  * `ai_agent` 同时消费 `system_tick` 和 `market_events`，作为其决策的输入。

* **主题 (Topic)**：事件的逻辑分类。项目定义了清晰的主题来隔离不同的业务流：

  * `order_commands`: 订单指令的专属通道。
  * `trade_executed`: 所有成交记录的公告板。
  * `system_ticks` 和 `market_events`: 驱动模拟世界运转的基础事件。

**3. EDA + Kafka 带来了什么？**

* **终极解耦**: `api_gateway` 完全不知道撮合引擎的存在，它只负责把订单“扔”进 Kafka。未来可以轻易地用一个新的撮合引擎换掉旧的，而无需改动 `api_gateway` 的任何代码。
* **削峰填谷**: 想象一下市场开盘瞬间，大量订单涌入。Kafka 可以作为巨大的缓冲区，稳定地接收所有订单，让后端的 `matching_engine` 可以按照自己的节奏来处理，避免了因瞬间流量过大而导致的系统崩溃。
* **可追溯性与重放**: Kafka 会将事件持久化存储一段时间。这意味着，如果 `data_recorder` 服务出现故障，修复后可以从上次失败的位置重新消费事件，保证数据不丢失。甚至可以重放所有历史事件来重建某个时刻的系统状态。

-----

#### **第三部分：导航——服务发现 (Service Discovery)**

现在我们有了多个独立的服务，并且它们通过 Kafka 进行通信。但还有一个问题：`api_gateway` 如何知道 Kafka 的地址？`data_recorder` 又如何知道 PostgreSQL 数据库的地址？

**1. 问题：地址的硬编码**

在目前的 `docker-compose.yml` 中，这些地址是作为环境变量硬编码进去的。例如 `KAFKA_BROKERS=kafka:9092`。

这种方式在开发和简单部署时很有效。但设想一下，如果系统需要弹性伸缩，比如 `matching_engine` 从 1 个实例扩展到 5 个，我们无法手动去更新所有依赖它的服务的配置。

**2. 解决方案：服务发现**

服务发现机制就像一个为微服务准备的、**实时的、自动化的“电话簿”**。

它的工作流程如下：

* **服务注册**: 每个服务实例（如一个 `matching_engine` 容器）在启动时，会向一个中心化的“服务注册中心”进行注册，告诉大家：“我是撮合引擎，我的地址是 `10.1.2.3:8080`，我还活着。”
* **服务查询**: 当 `api_gateway` 需要与撮合引擎通信时（虽然在架构中是通过 Kafka 解耦的，但我们以此为例），它会去问注册中心：“请给我一个可用的 `matching_engine` 的地址”。注册中心会返回一个健康的实例列表。

**3. 主流工具与未来展望**

* **Consul / etcd**: 这些是流行的服务发现工具，可以将它们作为新的服务加入到 Docker Compose 文件中。每个服务启动时向其注册，通信前向其查询。
* **Kubernetes**: 如果未来选择将项目部署到 Kubernetes，那么恭喜，服务发现是 K8s 的一项内置核心功能，无需任何额外配置即可使用。

通过引入服务发现， `arbitrage-engine` 系统将获得真正的弹性，能够自适应地处理服务实例的增减和故障，向着生产级高可用系统迈出关键一步。

-----

#### **第四部分：开发与维护的利器**

最后，我们来看两个在开发和项目管理中至关重要的实用工具。

##### **A. 使用 `mockall` 进行单元测试**

在测试中，我们需要将被测试的代码单元与它的外部依赖（如数据库、其他服务）隔离开来。`mockall` 是 Rust 中实现这一目标的最佳工具。

* **它是什么：** 一个模拟对象库，用于在测试中创建真实对象的“替身”。
* **为何重要：** 假设要测试 `ai_agent` 的决策逻辑。在单元测试中，不希望它真的去调用 `api_gateway`。`mockall` 允许创建一个假的 `api_gateway` 客户端，并精确控制它的行为：
    1. **模拟行为：** 可以设定这个假客户端在被调用时，返回一个预设的股票价格，或者模拟一次网络错误。
    2. **验证交互：** 可以断言 `ai_agent` 是否用正确的参数（比如股票代码）调用了价格查询接口，以及调用了多少次。
* **工作方式：** 通常，会为一个依赖定义一个 `trait`（接口），然后使用 `mockall` 的 `#[automock]` 属性，它就会在编译时自动为这个 `trait` 生成一个可配置的模拟版本，供在测试中使用。

##### **B. 使用符号链接（Symbolic Links）**

在重构项目时已经巧妙地运用了这一工具。

* **它是什么：** 文件系统层面的“快捷方式”或“指针”。它是一个特殊的小文件，内容就是指向另一个真实文件或目录的路径。
* **项目中的应用：** 当将脚本和 Docker 文件分别移动到 `scripts/` 和 `docker/` 目录后，为了不让旧的命令失效，在项目根目录创建了指向新位置的符号链接。

    ```bash
    # 这个在根目录的 "快捷方式" 指向了 scripts/ 目录下的真实文件
    ln -sf scripts/manage.sh .
    ```

* **为何巧妙：** 这实现了**向后兼容**。习惯于在根目录运行 `./manage.sh` 的用户或脚本可以无缝过渡，无需修改任何命令，这在协作和自动化流程中非常重要。

-----

### **总结**

通过这篇教程，我们以 `arbitrage-engine` 项目为例，层层递进地剖析了现代后端架构的几大核心概念：

* 我们用**微服务架构**将系统拆分成独立的、高内聚的功能单元。
* 我们用**事件驱动架构**作为这些服务间的协作模式，实现了极致的松耦合。
* 我们用 **Apache Kafka** 担当事件的传输中枢，保证了系统的高性能和可靠性。
* 我们展望了如何通过**服务发现**来管理服务的网络位置，赋予系统真正的弹性。
* 最后，我们了解了 **mockall** 和**符号链接** 这两个实用工具如何在开发和维护阶段提升效率和健壮性。
